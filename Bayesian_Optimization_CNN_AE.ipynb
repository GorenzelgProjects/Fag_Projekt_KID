{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network_calculation import Network_cal\n",
    "from CNN_generator import Epoch, Encoder, Decoder, EEGDataset\n",
    "from Save_BO import SaveData\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split, Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import GPyOpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Savedata = SaveData()\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "network_calc = Network_cal()\n",
    "train = Epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"train_data_1_30.npy\")\n",
    "train_labels = np.load(\"train_label_1_30.npy\").astype(np.int32)\n",
    "test_data = np.load(\"test_data_31_40.npy\")\n",
    "test_labels = np.load(\"test_label_31_40.npy\").astype(np.int32)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "#train_data = np.transpose(train_data, (1,2,0))\n",
    "\n",
    "train_data = train_data*1e5\n",
    "test_data = test_data*1e5\n",
    "train_dataset = EEGDataset(train_data, train_labels)\n",
    "test_dataset = EEGDataset(test_data, test_labels)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "#print(test_dataset[:,1])\n",
    "\n",
    "\n",
    "print(m)\n",
    "train_data, val_data = random_split(train_dataset, [math.floor(m*0.8), math.ceil(m*0.2)])\n",
    "#print(train_data[:5])\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = encoder(encoder_list, linear_int,in_channels = in_channels, out_channels = out_channels, encoded_space_dim = 35, fc2_input_dim = 35, layers=3, filter_size =32, kernel = (1,4), kernel_p = (1,2), stride = 2, stride_p = 2, padding = (0,1), padding_p = (0,0), pooling = True)\n",
    "D = decoder(decoder_list, linear_int,in_channels = in_channels, out_channels = out_channels, encoded_space_dim = 35, fc2_input_dim = 35, layers=3, filter_size =32, kernel = (1,4), kernel_p = (1,2), stride = 2, stride_p = 2, padding = (0,1), padding_p = (0,0), pooling = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Domain settings for architecture.\n",
    "\n",
    "Domain_archi = [{'name': 'in_channels', 'type': 'discrete', 'domain': encoder.in_channels}, #These domains are lists - Hence it will be lists in a list\n",
    "          {'name': 'out_channels', 'type': 'discrete', 'domain': encoder.out_channels}, #These domains are lists - Hence it will be lists in a list\n",
    "          {'name': 'encoded_space_dim', 'type': 'discrete', 'domain': encoder.encoded_space_dim},\n",
    "          {'name': 'fc2_input_dim', 'type': 'discrete', 'domain': encoder.fc2_input_dim},\n",
    "          {'name': 'layers', 'type': 'discrete', 'domain': encoder.layers},\n",
    "          {'name': 'kernel', 'type': 'discrete', 'domain': encoder.kernel},\n",
    "          {'name': 'kernel_p', 'type': 'discrete', 'domain': encoder.kernel_p},\n",
    "          {'name': 'stride', 'type': 'discrete', 'domain': encoder.stride},\n",
    "          {'name': 'stride_p', 'type': 'discrete', 'domain': encoder.stride_p},\n",
    "          {'name': 'padding', 'type': 'discrete', 'domain': encoder.padding},\n",
    "          {'name': 'padding_p', 'type': 'discrete', 'domain': encoder.padding_p},\n",
    "          {'name': 'pooling', 'type': 'discrete', 'domain': encoder.pooling}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Domain settings for hyperparameters\n",
    "\n",
    "Domain_hyper = [{'name': 'in_channels', 'type': 'discrete', 'domain': encoder.in_channels}, #These domains are lists - Hence it will be lists in a list\n",
    "          {'name': 'out_channels', 'type': 'discrete', 'domain': encoder.out_channels}, #These domains are lists - Hence it will be lists in a list\n",
    "          {'name': 'encoded_space_dim', 'type': 'discrete', 'domain': encoder.encoded_space_dim},\n",
    "          {'name': 'fc2_input_dim', 'type': 'discrete', 'domain': encoder.fc2_input_dim},\n",
    "          {'name': 'layers', 'type': 'discrete', 'domain': encoder.layers},\n",
    "          {'name': 'kernel', 'type': 'discrete', 'domain': encoder.kernel},\n",
    "          {'name': 'kernel_p', 'type': 'discrete', 'domain': encoder.kernel_p},\n",
    "          {'name': 'stride', 'type': 'discrete', 'domain': encoder.stride},\n",
    "          {'name': 'stride_p', 'type': 'discrete', 'domain': encoder.stride_p},\n",
    "          {'name': 'padding', 'type': 'discrete', 'domain': encoder.padding},\n",
    "          {'name': 'padding_p', 'type': 'discrete', 'domain': encoder.padding_p},\n",
    "          {'name': 'pooling', 'type': 'discrete', 'domain': encoder.pooling}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayersian_optimization():\n",
    "                                            #Domain: [{'name': 'batch_size', 'type': 'discrete', 'domain': batch_size},{}]\n",
    "                                            #param_list = [batch_size = tuple(np.arange(64,128,1)), learning_rate = tuple(np.arange(1,31,0.5)*1e-5)]\n",
    "\n",
    "\n",
    "    def __init__(self, domain=None,param_list=[],model=None,device_type='cuda'):\n",
    "        self.domain = domain\n",
    "        \n",
    "        self.param_list = param_list\n",
    "        self.model = model\n",
    "        self.device_type = device_type\n",
    "        super().__init__()                           \n",
    "    \n",
    "    def objective_function(self,x):\n",
    "\n",
    "        #print(x)\n",
    "        # we have to handle the categorical variables that is convert 0/1 to labels\n",
    "        # log2/sqrt and gini/entropy\n",
    "        param = x[0]\n",
    "        #print(int(param[0]),param[1])\n",
    "        if param[11] == True:\n",
    "            pooling = True\n",
    "        else:\n",
    "            pooling = False\n",
    "        # we have to handle the categorical variables\n",
    "        #if param[2] == 0:\n",
    "        #    max_f = 'log2'\n",
    "        #elif param[2] == 1:\n",
    "        # max_f = 'sqrt'\n",
    "        #else:\n",
    "        #  max_f = None\n",
    "\n",
    "        #if param[3] == 0:\n",
    "        #  crit = 'gini'\n",
    "        #else:\n",
    "        #crit = 'entropy'\n",
    "\n",
    "        #create the model\n",
    "        model = self.model(encoder, decoder, device)\n",
    "        device = torch.device(self.device_type)  # use cuda or cpu\n",
    "        model.to(device)\n",
    "        model2 = train(encoder, decoder, device) #dataloader, loss_fn, optimizer,n=10))\n",
    "        \n",
    "        # fit the model \n",
    "        \n",
    "        test_accuracy = model2.training()\n",
    "\n",
    "        #model.fit(Xtrain, ytrain)\n",
    "        print(test_accuracy)\n",
    "        return - test_accuracy\n",
    "\n",
    "    def bo(self,max_iter=15,exloration_weight=0.05,acquisition='EI'):\n",
    "        opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                                    domain = self.domain,         # box-constrains of the problem\n",
    "                                                    acquisition_type = acquisition,      # Select acquisition function MPI, EI, LCB\n",
    "                                                    )\n",
    "        opt.acquisition.exploration_weight=exloration_weight\n",
    "\n",
    "        opt.run_optimization(max_iter = max_iter) \n",
    "\n",
    "        x_best = opt.X[np.argmin(opt.Y)]\n",
    "        print(\"The best parameters obtained: batch_size=\" + str(x_best[0]) + \", learning_rate=\" + str(x_best[1]))\n",
    "        return x_best, architecture, hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
